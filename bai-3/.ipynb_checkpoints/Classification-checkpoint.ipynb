{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "uTcWNMoUnE81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTcWNMoUnE81",
    "outputId": "85c52206-b2e0-43dd-915a-2af6238b0899"
   },
   "outputs": [],
   "source": [
    "# mount gg drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a-a-RZ5Jm1bW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-a-RZ5Jm1bW",
    "outputId": "a1cb9aa4-8f38-45a6-cde0-ded7397560e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 123] The filename, directory name, or volume label syntax is incorrect: '<your folder path>'\n",
      "G:\\2021-1\\Xử lý ảnh\\Src\\DemoOpenCV\\Project\\bai-3\n"
     ]
    }
   ],
   "source": [
    "%cd <your folder path>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59b4bf7",
   "metadata": {
    "id": "b59b4bf7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn import svm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395fbd7c",
   "metadata": {
    "id": "395fbd7c"
   },
   "outputs": [],
   "source": [
    "# Function for normalizing data\n",
    "def normalize_data(input_data):\n",
    "    mu = input_data.mean(axis=0)\n",
    "    std = input_data.std(axis=0)\n",
    "    return (input_data-mu)/std, mu, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d4acfa",
   "metadata": {
    "id": "62d4acfa"
   },
   "outputs": [],
   "source": [
    "# Loading features\n",
    "train_data = np.load('Train_data.npz')\n",
    "test_data = np.load('Test_data.npz')\n",
    "\n",
    "x_train_all_features = train_data['x_train_all_features']\n",
    "y_train = train_data['y_train']\n",
    "\n",
    "x_test_all_features = test_data['x_test_all_features']\n",
    "y_test_all = test_data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72a2b41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b72a2b41",
    "outputId": "59049adf-9edf-49b0-b27a-2601553d585b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "# number classes of image\n",
    "print(len(set(y_test_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3ecb0d",
   "metadata": {
    "id": "3d3ecb0d"
   },
   "outputs": [],
   "source": [
    "# Number of features after PCA algorithm\n",
    "# reference: https://www.scielo.br/j/eins/a/yzFzBTrdgGrv46hGsnzKssd/?lang=en#:~:text=Principal%20Components%20Analysis%20(PCA)(,similarities%20and%20differences%20are%20emphasized.\n",
    "num_features = 47\n",
    "\n",
    "# PCA on Train data\n",
    "# reduce dimension of train data\n",
    "(U, S, V) = torch.pca_lowrank(torch.tensor(x_train_all_features), q = num_features)\n",
    "\n",
    "new_data_train = torch.matmul(torch.tensor(x_train_all_features), V[:, :num_features])\n",
    "x_train_non_normalized = new_data_train.numpy()\n",
    "\n",
    "# PCA on Test data\n",
    "new_data_test = torch.matmul(torch.tensor(x_test_all_features), V[:, :num_features])\n",
    "x_test_non_normalized = new_data_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e32b8117",
   "metadata": {
    "id": "e32b8117"
   },
   "outputs": [],
   "source": [
    "# Normalizing features\n",
    "x_train_svc, mu, std = normalize_data(x_train_non_normalized)\n",
    "x_test_svc = (x_test_non_normalized - mu) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80248fd3",
   "metadata": {
    "id": "80248fd3"
   },
   "outputs": [],
   "source": [
    "# Split test set into validation and test for the purpose of hyperparameter tuning\n",
    "# you can modifiy these parameters to fine tune model\n",
    "x_val, x_test, y_val, y_test = train_test_split( x_test_svc, y_test_all, test_size = 0.5, random_state = 15 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4312861",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4312861",
    "outputId": "8fc862e6-d991-45b1-a980-9bb94290becc"
   },
   "outputs": [],
   "source": [
    "# find C param to get best model\n",
    "# reference: https://numpy.org/doc/stable/reference/generated/numpy.logspace.html\n",
    "C_all = np.logspace(-3, 2, num=100)\n",
    "acc_all = np.zeros_like(C_all)\n",
    "\n",
    "# Cross-validation for hyperparameter C\n",
    "for i in range(len(C_all)):\n",
    "\n",
    "    # Create an svm Classifier\n",
    "    clf = svm.SVC( C = C_all[i], kernel = 'linear')\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf.fit( x_train_svc, y_train.ravel() )\n",
    "\n",
    "    # Predict the response for validaiton data\n",
    "    y_pred_val = clf.predict(x_val)\n",
    "\n",
    "    same_pred = np.sum(y_pred_val == y_val.squeeze())\n",
    "    acc = same_pred / len(y_pred_val)\n",
    "    acc_all[i] = acc\n",
    "\n",
    "pos = np.argmax(acc_all)\n",
    "best_C = C_all[pos]\n",
    "print( 'Best value for hyperparameter C: ' + str(best_C) )\n",
    "\n",
    "# SVM classifier for best value of the hyperparameter C\n",
    "clf = svm.SVC( C = best_C, kernel = 'linear')\n",
    "# train model\n",
    "clf.fit( x_train_svc, y_train.ravel() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95144472",
   "metadata": {
    "id": "95144472",
    "outputId": "7f7c1e58-f936-418e-fd77-423a4c311b42"
   },
   "outputs": [],
   "source": [
    "# Results on train dataset\n",
    "y_pred_train = clf.predict(x_train_svc)\n",
    "print(y_pred_train)\n",
    "print(y_train.squeeze())\n",
    "\n",
    "same_pred_train = np.sum(y_pred_train == y_train.squeeze())\n",
    "acc_train = same_pred_train / len(y_pred_train)\n",
    "# accuracy = total images classified correcly / total images in dataset\n",
    "print('Correct: ' + str( same_pred_train ) + '; Incorrect: ' + str( len(y_pred_train) - same_pred_train ) )\n",
    "print('Accuracy: ' + str(acc_train * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732ae0f",
   "metadata": {
    "id": "7732ae0f",
    "outputId": "f3c93c3e-b79f-4576-a27f-0f1457306897"
   },
   "outputs": [],
   "source": [
    "# Results on validation dataset\n",
    "y_pred_val = clf.predict(x_val)\n",
    "\n",
    "same_pred_val = np.sum(y_pred_val == y_val.squeeze())\n",
    "acc_val = same_pred_val / len(y_pred_val)\n",
    "\n",
    "print('Correct: ' + str( same_pred_val ) + '; Incorrect: ' + str( len(y_pred_val) - same_pred_val ) )\n",
    "print('Accuracy: ' + str(acc_val * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494e8a8",
   "metadata": {
    "id": "9494e8a8",
    "outputId": "bc564e4d-2541-4a3c-d03a-8ded0f854c30"
   },
   "outputs": [],
   "source": [
    "# Results on test dataset\n",
    "y_pred_test = clf.predict(x_test)\n",
    "\n",
    "same_pred_test = np.sum(y_pred_test == y_test.squeeze())\n",
    "acc_test = same_pred_test / len(y_pred_test)\n",
    "\n",
    "print('Correct: ' + str( same_pred_test ) + '; Incorrect: ' + str( len(y_pred_test) - same_pred_test ) )\n",
    "print('Accuracy: ' + str(acc_test * 100) + '%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyCharm (DemoOpenCV)",
   "language": "python",
   "name": "pycharm-c308c2e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
