{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "FeatureExtraction",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pycharm-c308c2e0",
   "language": "python",
   "display_name": "PyCharm (DemoOpenCV)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%cd <your folder path which contains data folder>"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOzVjmDUbpIK",
    "outputId": "4e13974b-48bf-4661-b716-803640e86515"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 123] The filename, directory name, or volume label syntax is incorrect: '<your folder path which contains data folder>'\n",
      "G:\\2021-1\\Xử lý ảnh\\Src\\DemoOpenCV\\Project\\bai-3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "718omFg4bAuJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "image_folder = \"./dtd/images\"\n",
    "\n",
    "label_file = \"./dtd/labels/labels_joint_anno.txt\"\n"
   ],
   "metadata": {
    "id": "3TD-5Jqgbmhc"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_data(label_file: str):\n",
    "    \"\"\"\n",
    "    Mapping image path with image class\n",
    "    \"\"\"\n",
    "    mapped_data = []\n",
    "    with open(label_file, 'r') as f:\n",
    "        data = f.readlines()\n",
    "        for line in data:\n",
    "            line_split = line.split(' ')\n",
    "            image_path = os.path.join(image_folder, line_split[0])\n",
    "            image_class = line_split[1]\n",
    "            mapped_data.append((image_path, image_class))\n",
    "    return mapped_data\n"
   ],
   "metadata": {
    "id": "OVwW0YrQbuHP"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# alexnet model\n",
    "# reference: https://pytorch.org/vision/main/_modules/torchvision/models/alexnet.html\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(170),\n",
    "    transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]\n",
    ")\n",
    "img_to_tensor = transforms.ToTensor()"
   ],
   "metadata": {
    "id": "xTTXDwAcbwVB",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "outputId": "5223036d-b27b-48cb-ed84-d0648f46ead4"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_image_paths = []\n",
    "y_train = []\n",
    "test_image_paths = []\n",
    "y_test = []\n",
    "\n",
    "data = get_data(label_file)\n",
    "\n",
    "train_size = int(len(data) * 0.7)\n",
    "print(\"Number train images: \", train_size)\n",
    "print(\"Number test images: \", len(data) - train_size)\n",
    "# random dataset and seperate them to train dataset and test dataset\n",
    "np.random.shuffle(data)\n",
    "train_data = data[: train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "for el in train_data:\n",
    "    train_image_paths.append(el[0])\n",
    "    y_train.append(el[1])\n",
    "\n",
    "for el in test_data:\n",
    "    test_image_paths.append(el[0])\n",
    "    y_test.append(el[1])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "er85pOPkbysE",
    "outputId": "93a481d5-85e6-4632-9e59-ca93720dc223"
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number train images:  3947\n",
      "Number test images:  1693\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "print(alexnet.classifier)\n",
    "# Changing the output of the Alexnet model to output a 4096 dimensional feature vector\n",
    "alexnet.classifier[6] = Identity()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBPUGK6bb1bB",
    "outputId": "51cf86f0-1852-4546-f48c-ff78e466f30a"
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "all_train_image_features = torch.zeros((len(y_train), 4096))\n",
    "for i in range(train_size):\n",
    "    # load image\n",
    "    img = Image.open(train_image_paths[i])\n",
    "    # resize image to 150x150, if you have many resource of hardware, you can increate size of image to 300x300 => increase accuracy\n",
    "    img = img.resize((150, 150))\n",
    "    img_tensor = img_to_tensor(img).unsqueeze(0)\n",
    "    features = alexnet(img_tensor)\n",
    "    all_train_image_features[i, :] = alexnet(img_tensor)\n",
    "# Save train data to Train_data.npz\n",
    "np.savez('Train_data.npz', x_train_all_features=all_train_image_features.detach().numpy(), y_train=y_train)\n"
   ],
   "metadata": {
    "id": "_vj0M_r-b5uQ"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_test_image_features = torch.zeros((len(y_test), 4096))\n",
    "for i in range(len(test_data)):\n",
    "    img = Image.open(test_image_paths[i])\n",
    "    img = img.resize((150, 150))\n",
    "    img_tensor = img_to_tensor(img).unsqueeze(0)\n",
    "    features = alexnet(img_tensor)\n",
    "    all_test_image_features[i, :] = alexnet(img_tensor)\n",
    "\n",
    "# Save test data to Test_data.npz\n",
    "np.savez('Test_data.npz', x_test_all_features=all_test_image_features.detach().numpy(), y_test=y_test)\n"
   ],
   "metadata": {
    "id": "9XZnwvNOb5f0",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}