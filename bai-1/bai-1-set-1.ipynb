{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import required libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5d72301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea95f71d",
   "metadata": {},
   "source": [
    "# Read image\n",
    "Đọc ảnh bằng hàm cv.imread, với params bằng 0 (đọc với định dạng grayscale, đỡ phải convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d2958710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"././input/set1/\"\n",
    "\n",
    "current_image = cv.imread(path + \"4.png\", 0)\n",
    "\n",
    "# plt.imshow(current_image, cmap='gray')\n",
    "\n",
    "images = []\n",
    "\n",
    "for img_path in glob.glob(path + '*.png'):\n",
    "    images.append(cv.imread(img_path, 0))\n",
    "\n",
    "original_images = images"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Show all images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "def show_all_images(showed_images=images, image_titles=None):\n",
    "    if image_titles is None:\n",
    "        image_titles = []\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    columns = 5\n",
    "\n",
    "    for i, image in enumerate(showed_images):\n",
    "        print(i)\n",
    "        if image_titles[i]:\n",
    "            plt.title(image_titles[i])\n",
    "        plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "        plt.imshow(image, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2840/2096238946.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mshow_all_images\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moriginal_images\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2840/2720630944.py\u001B[0m in \u001B[0;36mshow_all_images\u001B[1;34m(showed_images, image_titles)\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimage\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshowed_images\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m         \u001B[1;32mif\u001B[0m \u001B[0mimage_titles\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m             \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage_titles\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msubplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mcolumns\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_all_images(original_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "83a32c2f",
   "metadata": {},
   "source": [
    "# Gaussian blur\n",
    "Remove salt&pepper noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d993c6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_gaussian_blur(image):\n",
    "    return cv.GaussianBlur(image, (7, 7), 0)\n",
    "\n",
    "\n",
    "images = list(map(apply_gaussian_blur, images))\n",
    "\n",
    "show_all_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90cc1d0",
   "metadata": {},
   "source": [
    "# Apply adaptive thresholding using the mean threshold method\n",
    "Sử dụng ngưỡng thích ứng cục bộ (adaptive local threshold). Thuật toán này sẽ tìm một ngưỡng phù hợp cho từng pixel. Phương pháp này sẽ không lấy 1 ngưỡng cố định cho toàn bộ ảnh, bởi lẽ do nguồn sáng của các vị trí trên ảnh là khác nhau. Nếu lấy 1 giá trị cố định thì sẽ có trường hợp phần nền bị đánh màu trắng, hạt gạo đánh màu đen. Do đó mới sử dụng adaptive threshold, nó sẽ tnihs giá trị trung bình của n điểm ảnh xung quanh 1 pixel đang xét, sau đó trừ cho hằng số C (n thường là số lẻ và C sẽ là số nguyên bất kỳ từ -255 đến 255). Các tham số n, C chúng em thử nhiều lần thôi chứ cũng ko có kinh nghiệm chọn cụ thể cho từng bài.\n",
    "\n",
    "\n",
    "- ADAPTIVE_THRESH_MEAN_C là cách tính giá trị ngưỡng theo trung bình như bên trên đã nói\n",
    "\n",
    "\n",
    "- Tham số thứ 5 là số điểm ảnh xung quanh để lấy trung bình (là số lẻ 3,5,7,..)\n",
    "\n",
    "\n",
    "- Tham số thứ 6 là hằng số C\n",
    "\n",
    "\n",
    "Đọc thêm về hàm adaptiveThreshold ở đây: https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c3ea4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# output_adapthresh = cv.adaptiveThreshold(blur, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 301, 0)  #set 1\n",
    "# output_adapthresh = cv.adaptiveThreshold(blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 201, 10) #set 2\n",
    "# plt.imshow(output_adapthresh, cmap='gray')\n",
    "def apply_thresh_hold(image):\n",
    "    return cv.adaptiveThreshold(image, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 301, 0)\n",
    "\n",
    "\n",
    "images = list(map(apply_thresh_hold, images))\n",
    "\n",
    "show_all_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209c257",
   "metadata": {},
   "source": [
    "# Fourier transform\n",
    "output đang không phải là uint8, mà hàm threshold của opencv thì require input dạng uint8. Tuy nhiên không thể convert trực tiếp từ output của fourier về np.uint8 được luôn vì mất tính chất của fourier trên ảnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de966690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft = cv.dft(np.float32(blur), flags=cv.DFT_COMPLEX_OUTPUT)\n",
    "# dft_shift = np.fft.fftshift(dft)\n",
    "#\n",
    "# rows, cols = current_image.shape\n",
    "# crow, ccol = int(rows / 2), int(cols / 2)\n",
    "#\n",
    "# mask = np.zeros((rows, cols, 2), np.uint8)\n",
    "# mask[crow - 30:crow + 30, ccol - 30:ccol + 30] = 1\n",
    "#\n",
    "# fshift = dft_shift * mask\n",
    "# f_ishift = np.fft.ifftshift(fshift)\n",
    "# img_back = cv.idft(f_ishift)\n",
    "# img_back = cv.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n",
    "#\n",
    "# plt.imshow(img_back, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171345f5",
   "metadata": {},
   "source": [
    "# Morphological erosion\n",
    "Xói mòn nhằm loại bỏ những pixel nhiễu xung quanh đối tượng làm cho phần viền đối tượng trở nên mịn hơn, nhỏ hơn và tách được các đối tượng chạm vào nhau\n",
    "\n",
    "kernel sẽ trượt qua tất cả pixel của ảnh. Một pixel được set là 1 nếu tất cả các pixel trong kernel là 1 và ngược lại sẽ bị chuyển thành 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = np.ones((13,13),np.uint8) #set 2\n",
    "def apply_morphological_erosion(image):\n",
    "    kernel = np.ones((5, 5), np.uint8)  #set 1\n",
    "    return cv.erode(image, kernel)\n",
    "\n",
    "images = list(map(apply_morphological_erosion, images))\n",
    "\n",
    "show_all_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f1e10",
   "metadata": {},
   "source": [
    "# Add counting number to each contour function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b1296",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "titles = []\n",
    "def apply_find_contours(image):\n",
    "\n",
    "    contours, _ = cv.findContours(image, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)  #set 1\n",
    "    titles.append('Counted contours: ' + str(len(contours)))\n",
    "\n",
    "    # Draw contour\n",
    "    output_contour = cv.cvtColor(image, cv.COLOR_GRAY2BGR)\n",
    "    return cv.drawContours(output_contour, contours, -1, (0, 0, 255), 2)\n",
    "\n",
    "images = list(map(apply_find_contours, images))\n",
    "\n",
    "show_all_images(original_images)\n",
    "show_all_images(images, titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-c308c2e0",
   "language": "python",
   "display_name": "PyCharm (DemoOpenCV)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}